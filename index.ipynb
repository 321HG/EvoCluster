{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"index.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IiNG95DSmRmt","colab_type":"text"},"source":["<h1>EvoCluster</h1>\n","An Open-Source Nature-Inspired Optimization Clustering Framework in Python"]},{"cell_type":"markdown","metadata":{"id":"hKzyadcdm6yw","colab_type":"text"},"source":["EvoCluster is an open source and cross-platform framework implemented in Python which includes the most well-known and recent nature-inspired metaheuristic  optimizers  that  are  customized  to  perform  partitional  clustering tasks.  \n","\n","The  goal  of  this  framework  is  to  provide  a  user-friendly  and  customizable implementation of the metaheuristic based clustering algorithms which can be utilized by experienced and non-experienced users for different applications.\n","\n","The framework can also be used by researchers who can benefit from the implementation of the metaheuristic optimizers for their research studies. \n","\n","EvoCluster can be extended by designing other optimizers, including more objective func-tions, adding other evaluation measures, and using more data sets. \n","\n","The current implementation  of  the  framework  includes  ten  metaheristic  optimizers,  thirtydatasets,  five  objective  functions,  and  twelve  evaluation  measures.  "]},{"cell_type":"markdown","metadata":{"id":"2zQnPqDUujil","colab_type":"text"},"source":["The full list of implemented optimizers is available here https://github.com/7ossam81/EvoloPy/wiki/List-of-optimizers"]},{"cell_type":"markdown","metadata":{"id":"ehxW3t0puwpm","colab_type":"text"},"source":["<h2>Features</h2>"]},{"cell_type":"markdown","metadata":{"id":"TufeO-Rturq8","colab_type":"text"},"source":["*   Ten nature-inspired metaheuristic optimizers are implemented.\n","*   The implimentation uses the fast array manipulation using [NumPy] (http://www.numpy.org/).\n","*   Matrix support using [SciPy's] (https://www.scipy.org/) package.\n","*   More optimizers are comming soon"]},{"cell_type":"markdown","metadata":{"id":"oG2TRdx-vf8m","colab_type":"text"},"source":["<h2>Installation<//h2>"]},{"cell_type":"markdown","metadata":{"id":"_XpMUOZNvi9H","colab_type":"text"},"source":["Python 3.xx is required."]},{"cell_type":"markdown","metadata":{"id":"f_PVAZC6v7px","colab_type":"text"},"source":["<h2>GitHub</h2>"]},{"cell_type":"markdown","metadata":{"id":"aW_66ovkv2ev","colab_type":"text"},"source":["Clone the Git repository from GitHub:\n","git clone https://github.com/RaneemQaddoura/EvoCluster.git"]},{"cell_type":"code","metadata":{"id":"QgrmE2wEyC_X","colab_type":"code","colab":{}},"source":["!git clone https://github.com/RaneemQaddoura/EvoCluster.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yVUbtjcyiZR","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"EvoCluster/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFF9ioDfyppV","colab_type":"code","colab":{}},"source":["# Select optimizers\n","CSSA= False\n","CPSO= True\n","CGA= True\n","CBAT= False\n","CFFA=False\n","CGWO=False\n","CWOA=False\n","CMVO=False\n","CMFO=False\n","CCS=False\n","optimizer=[CSSA, CPSO, CGA, CBAT, CFFA, CGWO, CWOA, CMVO, CMFO, CCS]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SuWo96bB6ohe","colab_type":"code","colab":{}},"source":["# Select objective function\n","SSE=True\n","TWCV=True\n","SC=False\n","DB=False\n","DI=False\n","objectivefunc=[SSE, TWCV, SC, DB, DI] "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQpzhArU65Px","colab_type":"code","colab":{}},"source":["dataset_List = [\"iris.csv\",\"aggregation.csv\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQyWvdS3Ipgt","colab_type":"code","colab":{}},"source":["# Select number of repetitions for each experiment. \n","# To obtain meaningful statistical results, usually 30 independent runs are executed for each algorithm.\n","NumOfRuns=3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2djrIRh26sKB","colab_type":"code","colab":{}},"source":["# Select general parameters for all optimizers (population size, number of iterations) ....\n","params = {'PopulationSize' = 50, 'Iterations'= 100}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJb075Np62GM","colab_type":"code","colab":{}},"source":["#Export results?\n","export_flags = {'Export_avg'=True,'Export_details'=True}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"APzDcxiwI8A2","colab_type":"code","colab":{}},"source":["from optimizer_run import run_optimizer\n","run_optimizer(optimizer, objectivefunc, dataset_List, NumOfRuns, params, export_flags)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XRKFptuXvnxW","colab_type":"text"},"source":["<h2>Importing libraries</h2>"]},{"cell_type":"code","metadata":{"id":"Ys25SEnsz3O3","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import CSSA as cssa\n","import CPSO as cpso\n","import CGA as cga\n","import CBAT as cbat\n","import CFFA as cffa\n","import CGWO as cgwo\n","import CWOA as cwoa\n","import CMVO as cmvo\n","import CMFO as cmfo\n","import CCS as ccs\n","import objectives\n","import measures\n","import numpy\n","import time\n","import csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TWJQhVFFopn","colab_type":"code","colab":{}},"source":["# the directory where the dataset is stored\n","directory = \"datasets/\" \n","#Automaticly generated name by date and time\n","ExportToFile=\"experiment \"+time.strftime(\"%Y-%m-%d-%H-%M-%S\")+\".csv\" \n","ExportToFileDetails=\"experiment \"+time.strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_details.csv\" \n","ExportToFileDetailsLabels=\"experiment \"+time.strftime(\"%Y-%m-%d-%H-%M-%S\")+\"_details_Labels.csv\" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IO1X8diJ68AS","colab_type":"code","colab":{}},"source":["def selector(algo,func_details, k, f, popSize,Iter, points):\n","    function_name=func_details[0]\n","    lb=0\n","    ub=1\n","    \n","    if(algo==0):\n","        x=cssa.SSA(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==1):\n","        x=cpso.PSO(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==2):\n","        x=cga.GA(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==3):\n","        x=cbat.BAT(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==4):\n","        x=cffa.FFA(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==5):\n","        x=cgwo.GWO(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==6):\n","        x=cwoa.WOA(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==7):\n","        x=cmvo.MVO(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==8):\n","        x=cmfo.MFO(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    if(algo==9):\n","        x=ccs.CS(getattr(objectives, function_name),lb,ub,k * f,popSize,Iter, k, points)        \n","    return x    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXrKT0Bx6-Hj","colab_type":"code","colab":{}},"source":["# CSV Header for for the cinvergence \n","CnvgHeader=[]\n","\n","# Check if it works at least once\n","Flag=False\n","Flag_details=False\n","Flag_details_Labels=False\n","\n","dataset_len = len(dataset_List)\n","\n","k = [-1] * dataset_len\n","f = [-1] * dataset_len\n","points= [0] * dataset_len\n","labelsTrue = [0] * dataset_len\n","\n","for l in range(0,Iterations):\n","\tCnvgHeader.append(\"Iter\"+str(l+1))\n","  \n","#read all datasets\n","for h in range(dataset_len):\n","        \n","    # Read the dataset file and generate the points list and true values \n","    rawData = open(directory + dataset_List[h], 'rt')\n","    data = numpy.loadtxt(rawData, delimiter=\",\")\n","    \n","    \n","    nPoints, nValues = data.shape #Number of points and Number of values for each point\n","    f[h] = nValues - 1 #Dimension value\n","    k[h] = len(numpy.unique(data[:,-1]))#k: Number of clusters\n","    points[h] = data[:,:-1].tolist() #list of points\n","    labelsTrue[h] = data[:,-1].tolist() #List of actual cluster of each points (last field)\n","    \n","    #points =(preprocessing.normalize(points, norm='max', axis=0) * 200) - 100\n","    points[h] =preprocessing.normalize(points[h], norm='max', axis=0)\n","\n","for i in range (0, len(optimizer)):\n","    for j in range (0, len(objectivefunc)):\n","        if((optimizer[i]==True) and (objectivefunc[j]==True)): # start experiment if an optimizer and an objective function is selected\n","           for h in range(len(dataset_List)):     \n","                HS = [0]*NumOfRuns     \n","                CS = [0]*NumOfRuns\n","                VM = [0]*NumOfRuns \n","                AMI = [0]*NumOfRuns \n","                ARI = [0]*NumOfRuns    \n","                Fmeasure = [0]*NumOfRuns   \n","                SC = [0]*NumOfRuns   \n","                accuracy = [0]*NumOfRuns   \n","                DI = [0]*NumOfRuns   \n","                DB = [0]*NumOfRuns   \n","                stdev = [0]*NumOfRuns   \n","                exSSE = [0]*NumOfRuns \n","                exTWCV = [0]*NumOfRuns\n","                purity = [0]*NumOfRuns\n","                entropy = [0]*NumOfRuns\n","                convergence = [0]*NumOfRuns\n","                executionTime = [0]*NumOfRuns\n","                #Agg = [0]*NumOfRuns\n","                \n","                for z in range (0,NumOfRuns):\n","                    print(\"Run no.: \" + str(z)) \n","                    \n","                    func_details=objectives.getFunctionDetails(j)\n","                    x=selector(i,func_details, k[h], f[h], PopulationSize,Iterations, points[h])\n","                    \n","                    \n","                    HS[z] = measures.HS(labelsTrue[h],x.labelsPred)\n","                    CS[z] = measures.CS(labelsTrue[h],x.labelsPred)\n","                    VM[z] = measures.VM(labelsTrue[h],x.labelsPred)\n","                    AMI[z] = measures.AMI(labelsTrue[h],x.labelsPred)\n","                    ARI[z] = measures.ARI(labelsTrue[h],x.labelsPred)\n","                    Fmeasure[z] = measures.Fmeasure(labelsTrue[h],x.labelsPred)\n","                    SC[z] = measures.SC(points[h],x.labelsPred)\n","                    accuracy[z] = measures.accuracy(labelsTrue[h],x.labelsPred)\n","                    DI[z] = measures.DI(points[h], x.labelsPred)\n","                    DB[z] = measures.DB(points[h], x.labelsPred)\n","                    stdev[z] = measures.stdev(x.bestIndividual,x.labelsPred, k[h], points[h])\n","                    exSSE[z] = measures.SSE(x.bestIndividual, x.labelsPred, k[h], points[h])\n","                    exTWCV[z] = measures.TWCV(x.bestIndividual, x.labelsPred, k[h], points[h])\n","                    purity[z] = measures.purity(labelsTrue[h],x.labelsPred)\n","                    entropy[z] = measures.entropy(labelsTrue[h],x.labelsPred)\n","                    #Agg[z] = float(\"%0.2f\"%(float(\"%0.2f\"%(HS[z] + CS[z] + VM[z] + AMI[z] + ARI[z])) / 5))\n","                    \n","                    executionTime[z] = x.executionTime\n","                    convergence[z] = x.convergence\n","                    optimizerName = x.optimizer\n","                    objfname = x.objfname\n","                    \n","                    \n","                    if(Export_details==True):\n","                        with open(ExportToFileDetailsLabels, 'a',newline='\\n') as out_details_labels:\n","                            writer_details = csv.writer(out_details_labels,delimiter=',')\n","                            if (Flag_details_Labels==False): # just one time to write the header of the CSV file\n","                                header_details= numpy.concatenate([[\"Dataset\", \"Optimizer\",\"objfname\"]])\n","                                writer_details.writerow(header_details)\n","                                Flag_details_Labels = True\n","                            a=numpy.concatenate([[dataset_List[h], optimizerName, objfname],x.labelsPred])  \n","                            writer_details.writerow(a)\n","                        out_details_labels.close()\n","                        \n","                        with open(ExportToFileDetails, 'a',newline='\\n') as out_details:\n","                            writer_details = csv.writer(out_details,delimiter=',')\n","                            if (Flag_details==False): # just one time to write the header of the CSV file\n","                                header_details= numpy.concatenate([[\"Dataset\", \"Optimizer\",\"objfname\",\"ExecutionTime\",\"SSE\",\"Purity\",\"Entropy\",\"HS\",\"CS\",\"VM\",\"AMI\",\"ARI\",\"Fmeasure\",\"TWCV\",\"SC\",\"Accuracy\",\"DI\",\"DB\",\"STDev\"],CnvgHeader])\n","                                writer_details.writerow(header_details)\n","                                Flag_details = True\n","                            a=numpy.concatenate([[dataset_List[h], optimizerName, objfname, float(\"%0.2f\"%(executionTime[z])), \n","                                  float(\"%0.2f\"%(exSSE[z])), float(\"%0.2f\"%(purity[z])), float(\"%0.2f\"%(entropy[z])), float(\"%0.2f\"%(HS[z])), \n","                                  float(\"%0.2f\"%(CS[z])),  float(\"%0.2f\"%(VM[z])),  float(\"%0.2f\"%(AMI[z])),  float(\"%0.2f\"%(ARI[z])), \n","                                  float(\"%0.2f\"%(Fmeasure[z])),  float(\"%0.2f\"%(exTWCV[z])),  float(\"%0.2f\"%(SC[z])),  float(\"%0.2f\"%(accuracy[z])),  float(\"%0.2f\"%(DI[z])), \n","                                  float(\"%0.2f\"%(DB[z])), float(\"%0.2f\"%(stdev[z]))],numpy.around(convergence[z],decimals=2)])  \n","                            writer_details.writerow(a)\n","                        out_details.close()\n","                    \n","            \n","                if(Export==True):\n","                    with open(ExportToFile, 'a',newline='\\n') as out:\n","                        writer = csv.writer(out,delimiter=',')\n","                        if (Flag==False): # just one time to write the header of the CSV file\n","                            header= numpy.concatenate([[\"Dataset\", \"Optimizer\",\"objfname\",\"ExecutionTime\",\"SSE\",\"Purity\",\"Entropy\",\"HS\",\"CS\",\"VM\",\"AMI\",\"ARI\",\"Fmeasure\",\"TWCV\",\"SC\",\"Accuracy\",\"DI\",\"DB\",\"STDev\"],CnvgHeader])\n","                            writer.writerow(header)\n","                                        \n","                        avgSSE = str(float(\"%0.2f\"%(sum(exSSE) / NumOfRuns)))\n","                        avgTWCV = str(float(\"%0.2f\"%(sum(exTWCV) / NumOfRuns)))\n","                        avgPurity = str(float(\"%0.2f\"%(sum(purity) / NumOfRuns)))\n","                        avgEntropy = str(float(\"%0.2f\"%(sum(entropy) / NumOfRuns)))\n","                        avgHomo = str(float(\"%0.2f\"%(sum(HS) / NumOfRuns)))\n","                        avgComp = str(float(\"%0.2f\"%(sum(CS) / NumOfRuns)))\n","                        avgVmeas = str(float(\"%0.2f\"%(sum(VM) / NumOfRuns)))\n","                        avgAMI = str(float(\"%0.2f\"%(sum(AMI) / NumOfRuns)))\n","                        avgARI = str(float(\"%0.2f\"%(sum(ARI) / NumOfRuns)))\n","                        avgFmeasure = str(float(\"%0.2f\"%(sum(Fmeasure) / NumOfRuns)))\n","                        avgSC = str(float(\"%0.2f\"%(sum(SC) / NumOfRuns)))\n","                        avgAccuracy = str(float(\"%0.2f\"%(sum(accuracy) / NumOfRuns)))\n","                        avgDI = str(float(\"%0.2f\"%(sum(DI) / NumOfRuns)))\n","                        avgDB = str(float(\"%0.2f\"%(sum(DB) / NumOfRuns)) )    \n","                        avgStdev = str(float(\"%0.2f\"%(sum(stdev) / NumOfRuns)))                \n","                        #avgAgg = str(float(\"%0.2f\"%(sum(Agg) / NumOfRuns)))\n","                        \n","                        avgExecutionTime = float(\"%0.2f\"%(sum(executionTime) / NumOfRuns))\n","                        avgConvergence = numpy.around(numpy.mean(convergence, axis=0, dtype=numpy.float64), decimals=2).tolist()\n","                        a=numpy.concatenate([[dataset_List[h], optimizerName,objfname,avgExecutionTime,avgSSE,avgPurity,avgEntropy,avgHomo, avgComp, avgVmeas, avgAMI, avgARI, avgFmeasure, avgTWCV, avgSC, avgAccuracy, avgDI, avgDB, avgStdev],avgConvergence])\n","                        writer.writerow(a)\n","                    out.close()\n","                Flag=True # at least one experiment\n","                    \n","if (Flag==False): # Faild to run at least one experiment\n","    print(\"No Optomizer or Cost function is selected. Check lists of available optimizers and cost functions\") \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4a9BEd5b74_U","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}